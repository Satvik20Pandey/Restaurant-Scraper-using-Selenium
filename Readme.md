Restaurant Scraper using Selenium
ğŸ“Œ Project Overview
This project scrapes restaurant data from Google search results using Selenium and displays the retrieved data on a webpage. It mimics human-like browsing behavior to reduce bot detection and ensure smoother data extraction.

ğŸ›  Features
âœ… Scrapes multiple restaurants from Google Search

âœ… Uses random delays and scrolling to mimic human behavior

âœ… Stores restaurant data in a CSV file

âœ… Automatically creates required directories

âœ… Displays the scraped data on a web page

ğŸ“‚ Folder Structure
ğŸ“‚ Scrape Data
â”œâ”€â”€ ğŸ“‚ static                # Stores scraped data
â”‚   â””â”€â”€ restaurants_new_delhi.csv  
â”œâ”€â”€ ğŸ“‚ templates             # Contains HTML file for UI
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ scraper.py              # Main script to scrape data
â”œâ”€â”€ app.py                  # Flask app to display data
â”œâ”€â”€ requirements.txt        # List of dependencies
â””â”€â”€ README.md               # Project documentation
ğŸš€ Installation & Usage
1ï¸âƒ£ Clone the Repository
git clone https://github.com/yourusername/restaurant-scraper.git
cd restaurant-scraper
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Run the Scraper
python scraper.py
This will scrape restaurant data from Google and save it in static/restaurants_new_delhi.csv.

4ï¸âƒ£ Start the Web Application
python app.py
Now, open http://127.0.0.1:5000/ in your browser to see the restaurant data.

ğŸ–¥ Technologies Used
Python (Selenium, Flask, Pandas)

HTML & CSS (Frontend UI)

CSV (Data Storage)

âš ï¸ Notes
Ensure Google Chrome and Chromedriver are installed.

If you face the OSError: Cannot save file into a non-existent directory, manually create a static folder.

Google may block excessive requests. If CAPTCHA appears frequently, try using proxies or different user-agents.

ğŸš€ Happy Scraping! ğŸ¯